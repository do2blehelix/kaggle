# The Titanic :ship:

> Kaggle Data Exploration and Competition for Predicting Survival. Competition Link and Data details found [here](https://www.kaggle.com/c/titanic)

## Project Motivation
This is the perfect #StarterKit in the world of Data Science. Presenting the most famous Kaggle competition for which there have been tens of thousands of minds submissions. It looks simple but getting a high accuracy score is difficult. Here's my take on this.

## File Description
All the required files are to be found in this repository.
* The **Pytanic** file contains the Exploration of the Training data and submission of the Testing data in **Jupyter Notebook**
* The **TitRanic** file contains a different approach in **R**
* **train** is the training set to be used for training the models
* **test** is the file to be used for predicting the *"Survived"* variable.

## Results
Your submission scored 0.81339. You can find it [here](https://www.kaggle.com/c/titanic/leaderboard)

## Installation
Most of the libraries are taken care of if Anaconda is already installed.
For XGBoost, use code `pip install XGBoost` in the Anaconda prompt

## Acknowledgement
Look out for Kaggle Notebooks [HERE](https://www.kaggle.com/c/titanic/notebooks). Lots of different ideas can be found there.


###### Note: This is a work in progress and I continue to strive to achieve better results. So some columns built in the data preparation might be excluded from the model.


